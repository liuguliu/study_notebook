{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsERpktwOX7ym0XdkCHCXT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuguliu/study_notebook/blob/main/Transformer_model_explorer_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3itfYFViIvh"
      },
      "outputs": [],
      "source": [
        "import torch # Import PyTorch\n",
        "import torch.nn as nn # Import the NN (neural network) library from PyTorch\n",
        "import torch.optim as optim # Import the optimizer (for training) from PyTorch\n",
        "import pprint # Import Pretty Print Library for formatted output (Pprint)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to obtain training data, vocab and mapping from word to index and vice versa\n",
        "def get_data_and_vocab():\n",
        "    # Define training data\n",
        "    training_data = {\n",
        "        \"how are you\": \"i am fine <end>\",\n",
        "        \"who is john\": \"a nice person <end>\",\n",
        "        \"who is nice\": \"john <end>\",\n",
        "        \"where is john\": \"at home <end>\",\n",
        "        \"how is john\": \"i dont know <end>\",\n",
        "        \"who are you\": \"mini gpt model <end>\"\n",
        "    }\n",
        "\n",
        "    # Extract input and target phrases\n",
        "    data_words = [k for k, _ in training_data.items()]\n",
        "    target_words = [v for _, v in training_data.items()]\n",
        "\n",
        "    # Build vocabulary from training data\n",
        "    vocabulary_words = list(set([element.lower() for nestedlist in [x.split(\" \") for x in data_words] for element in nestedlist] + [element.lower() for nestedlist in [x.split(\" \") for x in target_words] for element in nestedlist]))\n",
        "\n",
        "    # Ensure <end> token is at the end of vocabulary list, and there's a blank at the beginning\n",
        "    vocabulary_words.remove(\"<end>\")\n",
        "    vocabulary_words.append(\"<end>\")\n",
        "    vocabulary_words.insert(0, \"\")\n",
        "\n",
        "    # Create mappings from word to index and index to word\n",
        "    word_to_ix = {vocabulary_words[k].lower(): k for k in range(len(vocabulary_words))}\n",
        "    word_to_ix_g = word_to_ix\n",
        "    ix_to_word = {v: k for k, v in word_to_ix.items()}\n",
        "    ix_to_word_g = ix_to_word\n",
        "\n",
        "    # Return all the necessary data and mappings\n",
        "    return training_data, data_words, target_words, vocabulary_words, word_to_ix, ix_to_word"
      ],
      "metadata": {
        "id": "ldVBKYKTidVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert a batch of sequences of words to a tensor of indices\n",
        "def words_to_tensor(seq_batch, device=None):\n",
        "    global word_to_ix\n",
        "    index_batch = []\n",
        "\n",
        "    # Loop over sequences in the batch\n",
        "    for seq in seq_batch:\n",
        "        word_list = seq.lower().split(\" \")\n",
        "        indices = [word_to_ix[word] for word in word_list if word in word_to_ix]\n",
        "        t = torch.tensor(indices)\n",
        "        if device is not None:\n",
        "            t = t.to(device)  # Transfer tensor to the specified device\n",
        "        index_batch.append(t)\n",
        "\n",
        "    # Pad tensors to have the same length\n",
        "    return pad_tensors(index_batch)\n",
        "\n",
        "# Function to convert a tensor of indices to a list of sequences of words\n",
        "def tensor_to_words(tensor):\n",
        "    index_batch = tensor.cpu().numpy().tolist()\n",
        "    res = []\n",
        "    for indices in index_batch:\n",
        "        words = []\n",
        "        for ix in indices:\n",
        "            words.append(ix_to_word[ix].lower())  # Convert index to word\n",
        "            if ix == word_to_ix[\"<end>\"]:\n",
        "                break  # Stop when <end> token is encountered\n",
        "        res.append(\" \".join(words))\n",
        "    return res\n",
        "\n",
        "# Function to pad a list of tensors to the same length\n",
        "def pad_tensors(list_of_tensors):\n",
        "    tensor_count = len(list_of_tensors) if not torch.is_tensor(list_of_tensors) else list_of_tensors.shape[0]\n",
        "    max_dim = max(t.shape[0] for t in list_of_tensors)  # Find the maximum length\n",
        "    res = []\n",
        "    for t in list_of_tensors:\n",
        "        # Create a zero tensor of the desired shape\n",
        "        res_t = torch.zeros(max_dim, *t.shape[1:]).type(t.dtype).to(t.device)\n",
        "        res_t[:t.shape[0]] = t  # Copy the original tensor into the padded tensor\n",
        "        res.append(res_t)\n",
        "\n",
        "    # Concatenate tensors along a new dimension\n",
        "    res = torch.cat(res)\n",
        "    firstDim = len(list_of_tensors)\n",
        "    secondDim = max_dim\n",
        "\n",
        "    # Reshape the result to have the new dimension first\n",
        "    return res.reshape(firstDim, secondDim, *res.shape[1:])\n"
      ],
      "metadata": {
        "id": "3buk_Exfihx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Self-Attention module\n",
        "class SelfAttention(nn.Module):\n",
        "    def __init__(self, embed_size, head_count):\n",
        "        super(SelfAttention, self).__init__()\n",
        "        self.embed_size = embed_size  # Size of word embeddings\n",
        "        self.head_count = head_count  # Number of attention heads\n",
        "\n",
        "        # Create linear layers for query, key and value projections for each head\n",
        "        self.query_layers = nn.ModuleList([nn.Linear(embed_size, embed_size, bias=False) for _ in range(head_count)])\n",
        "        self.key_layers = nn.ModuleList([nn.Linear(embed_size, embed_size, bias=False) for _ in range(head_count)])\n",
        "        self.value_layers = nn.ModuleList([nn.Linear(embed_size, embed_size, bias=False) for _ in range(head_count)])\n",
        "\n",
        "        self.fc_out = nn.Linear(head_count * embed_size, embed_size)  # Final linear layer to combine head outputs\n",
        "    def forward(self, embeddings):\n",
        "        batch_size, token_count = embeddings.shape[:2]\n",
        "        qkvs = torch.zeros(self.head_count, 3, batch_size, token_count, self.embed_size).to(embeddings.device)\n",
        "\n",
        "        # Loop over heads and compute query, key and value projections\n",
        "        for i in range(self.head_count):\n",
        "            qkvs[i, 0] = self.query_layers[i](embeddings)\n",
        "            qkvs[i, 1] = self.key_layers[i](embeddings)\n",
        "            qkvs[i, 2] = self.value_layers[i](embeddings)\n",
        "\n",
        "        # Compute energy terms for each head, batch, and pair of tokens\n",
        "        energy = torch.zeros(self.head_count, batch_size, token_count, token_count).to(embeddings.device)\n",
        "        # Create a mask with false on and below the diagonal, and true above the diagonal\n",
        "        mask = torch.triu(torch.ones((token_count, token_count)), diagonal=1).bool()\n",
        "\n",
        "        for h in range(self.head_count):\n",
        "            for b in range(batch_size):\n",
        "                for i in range(token_count):\n",
        "                    for j in range(token_count):\n",
        "                        energy[h, b, i, j] = torch.dot(qkvs[h, 0, b, i], qkvs[h, 1, b, j])\n",
        "                energy[h, b] = energy[h, b].masked_fill(mask, float('-inf')) # Apply mask\n",
        "\n",
        "        # Compute attention scores\n",
        "        attention = torch.nn.functional.softmax(energy, dim=3)\n",
        "\n",
        "        # Compute weighted sum of values for each head and token\n",
        "        out = torch.zeros(batch_size, token_count, self.head_count, self.embed_size).to(embeddings.device)\n",
        "        for h in range(self.head_count):\n",
        "            for b in range(batch_size):\n",
        "                for i in range(token_count):\n",
        "                    for j in range(token_count):\n",
        "                        out[b, i, h] += (attention[h, b, i, j] * qkvs[h, 2, b, j])\n",
        "\n",
        "        # Reshape and pass through final linear layer\n",
        "        out = out.reshape(batch_size, token_count, self.head_count * self.embed_size)\n",
        "        return self.fc_out(out)\n"
      ],
      "metadata": {
        "id": "CDaysg17ij9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Transformer block module\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_size, head_count):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.attention = SelfAttention(embed_size, head_count)  # Self-attention layer\n",
        "        self.norm1 = nn.LayerNorm(embed_size)  # Layer normalization\n",
        "        self.norm2 = nn.LayerNorm(embed_size)  # Layer normalization\n",
        "\n",
        "        # Feed-forward neural network\n",
        "        self.feed_forward = nn.Sequential(\n",
        "            nn.Linear(embed_size, embed_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embed_size, embed_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, embeddings):\n",
        "        attention = self.attention(embeddings)\n",
        "\n",
        "        # Apply residual connections and layer normalization\n",
        "        out = self.norm1(attention + embeddings)\n",
        "        out = attention + self.feed_forward(out)\n",
        "        out = self.norm2(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "N6nyfs4RirQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Transformer module\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_layers, head_count):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.embed_size = embed_size  # Size of word embeddings\n",
        "        self.vocab_size = vocab_size  # Size of vocabulary\n",
        "        self.word_embedding = nn.Embedding(vocab_size, embed_size)  # Embedding layer\n",
        "\n",
        "        # List of transformer blocks\n",
        "        self.layers = nn.ModuleList(\n",
        "            [TransformerBlock(embed_size, head_count) for _ in range(num_layers)]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_size, vocab_size)  # Final linear layer to produce logits\n",
        "\n",
        "    def forward(self, input_tokens, mask=None):\n",
        "        batch_size, token_count = input_tokens.shape[:2]\n",
        "        out = input_tokens\n",
        "        # out = self.word_embedding(input_tokens)  # Obtain word embeddings\n",
        "\n",
        "        # # Compute position encodings and add to word embeddings\n",
        "        # positions = torch.arange(0, token_count).expand(batch_size, token_count).to(input_tokens.device)\n",
        "        # position_encoding = self.position_encoding(positions, self.embed_size)\n",
        "        # out += position_encoding.reshape(out.shape)\n",
        "\n",
        "        # Pass through each transformer block\n",
        "        for layer in self.layers:\n",
        "            out = layer(out)\n",
        "\n",
        "        # Produce logits for the final token in each sequence\n",
        "        out = self.fc_out(out[:, -1, :].reshape(batch_size, self.embed_size)).reshape(batch_size, self.vocab_size)\n",
        "        return torch.nn.functional.softmax(out, dim=1)  # Apply softmax to obtain probabilities\n",
        "\n",
        "    def position_encoding(self, positions, embed_size):\n",
        "        # Compute position encoding for each position and dimension\n",
        "        angle_rads = self.get_angles(\n",
        "            positions.unsqueeze(2).float(),\n",
        "            torch.arange(embed_size)[None, None, :].float().to(positions.device),\n",
        "            embed_size\n",
        "        )\n",
        "        sines = torch.sin(angle_rads[:, :, 0::2])  # Compute sine of angle for even dimensions\n",
        "        cosines = torch.cos(angle_rads[:, :, 1::2])  # Compute cosine of angle for odd dimensions\n",
        "        pos_encoding = torch.cat([sines, cosines], dim=-1)  # Concatenate sine and cosine values\n",
        "        pos_encoding = pos_encoding[None, ...]\n",
        "        return pos_encoding\n",
        "\n",
        "    def get_angles(self, pos, i, embed_size):\n",
        "        # Compute angle rate for each position and dimension\n",
        "        angle_rates = 1 / torch.pow(10000, (2 * (i//2)) / embed_size)\n",
        "        return pos * angle_rates\n"
      ],
      "metadata": {
        "id": "lKbUVzaMi5ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sbcQ9QPurL-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input: PyTorch model (Transformer module),\n",
        "# data: input tensor (batch_size x max_token_count)\n",
        "# targets: ground truth/expected output tensor (batch_size x max_token_count)\n",
        "# optimizer: PyTorch optimizer to use and criterion (which loss function to use)\n",
        "# Function to train the model recursively over each sequence and token\n",
        "def train_recursive(model, data, targets, optimizer, criterion):\n",
        "    model.train()  # Set model to training mode\n",
        "    optimizer.zero_grad()  # Zero the gradients\n",
        "    total_loss = 0  # Initialize total loss\n",
        "    batch_size, token_count, token_count_out = data.shape[0], data.shape[1], targets.shape[1]\n",
        "\n",
        "    # Loop over sequences in the batch\n",
        "    for b in range(batch_size):\n",
        "        end_encountered = False\n",
        "        cur_count = 0\n",
        "        # Loop over tokens in the sequence\n",
        "        while not end_encountered:\n",
        "            target_vector = torch.zeros(model.vocab_size).to(data.device)  # Initialize target vector\n",
        "\n",
        "            if cur_count != token_count_out:\n",
        "                expected_next_token_idx = targets[b, cur_count]  # Get index of expected next token\n",
        "                target_vector[expected_next_token_idx] = 1  # Set the corresponding element of the target vector to 1\n",
        "\n",
        "            # Concatenate current input and output tokens and pass through model\n",
        "            if cur_count > 0:\n",
        "                model_input = data[b].reshape(token_count).to(data.device)\n",
        "                part_of_output = targets[b, :cur_count].to(data.device)\n",
        "                model_input = torch.cat((model_input, part_of_output))\n",
        "            else:\n",
        "                model_input = data[b]\n",
        "            out = model(model_input.reshape(1, token_count + cur_count))\n",
        "\n",
        "            # Compute loss and accumulate total loss\n",
        "            loss = criterion(out, target_vector.reshape(out.shape))\n",
        "            total_loss += loss\n",
        "            cur_count += 1\n",
        "\n",
        "            # Stop when the end of the sequence is reached\n",
        "            if cur_count > token_count_out:\n",
        "                end_encountered = True\n",
        "\n",
        "    # Backpropagate gradients and update model parameters\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "    return total_loss.item() / batch_size\n"
      ],
      "metadata": {
        "id": "_r_DjXnhoYCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to demonstrate training and inference\n",
        "def example_training_and_inference():\n",
        "    # Get model hyperparameters from vocabulary size\n",
        "    vocab_size = len(word_to_ix)\n",
        "    embed_size = 512\n",
        "    num_layers = 4\n",
        "    heads = 3\n",
        "\n",
        "    # Create model, optimizer, and loss function\n",
        "    device = torch.device(\"cpu\")\n",
        "    model = Transformer(vocab_size, embed_size, num_layers, heads).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Convert training data to tensors\n",
        "    data = words_to_tensor(data_words, device=device)\n",
        "    targets = words_to_tensor(target_words, device=device)\n",
        "\n",
        "    # Train model for 55 epochs\n",
        "    for epoch in range(55):\n",
        "        avg_loss = train_recursive(model, data, targets, optimizer, criterion)\n",
        "        print(f'Epoch {epoch + 1}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Perform inference on training data\n",
        "    input_vector = words_to_tensor(data_words, device=device)\n",
        "    predicted_vector = infer_recursive(model, input_vector)\n",
        "    predicted_words = tensor_to_words(predicted_vector)\n",
        "\n",
        "    # Print training data and model output\n",
        "    print(\"\\n\\n\\n\")\n",
        "    print(\"Training Data:\")\n",
        "    pprint.pprint(training_data)\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"Model Inference:\")\n",
        "    result_data = {data_words[k]: predicted_words[k] for k in range(len(predicted_words))}\n",
        "    pprint.pprint(result_data)\n",
        "\n",
        "# Main function to call the demonstration function\n",
        "if __name__ == \"__main__\":\n",
        "    # Get training data and vocabulary\n",
        "    training_data, data_words, target_words, vocabulary_words, word_to_ix, ix_to_word = get_data_and_vocab()\n",
        "    print(data_words)\n",
        "    # Run the example training and inference function\n",
        "    example_training_and_inference()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "_Ab-5lXcohcd",
        "outputId": "203c1dfa-df50-4e44-fdfd-ee0ec9a6f026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['how are you', 'who is john', 'who is nice', 'where is john', 'how is john', 'who are you']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1x3 and 512x512)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-05f0dd4eeaa4>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# Run the example training and inference function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mexample_training_and_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-05f0dd4eeaa4>\u001b[0m in \u001b[0;36mexample_training_and_inference\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Train model for 55 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_recursive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {epoch + 1}, Loss: {avg_loss:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-43cfb2f6b949>\u001b[0m in \u001b[0;36mtrain_recursive\u001b[0;34m(model, data, targets, optimizer, criterion)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_count\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcur_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Compute loss and accumulate total loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-2600b21d5d60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_tokens, mask)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Pass through each transformer block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Produce logits for the final token in each sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-373f9034f77c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mattention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Apply residual connections and layer normalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-b7821bb141a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# Loop over heads and compute query, key and value projections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mqkvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mqkvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mqkvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x3 and 512x512)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rJR0bc6umZmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data, data_words, target_words, vocabulary_words, word_to_ix, ix_to_word = get_data_and_vocab()\n",
        "print(data_words)\n",
        "vocab_size = len(word_to_ix)\n",
        "print(vocab_size)\n",
        "vocab_size = 10\n",
        "embed_size = 128\n",
        "num_layers = 1\n",
        "heads = 2\n",
        "\n",
        "# Create model, optimizer, and loss function\n",
        "device = torch.device(\"cpu\")\n",
        "model = Transformer(vocab_size, embed_size, num_layers, heads).to(device)\n",
        "# print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uy5zBDACi5db",
        "outputId": "c1564d04-e510-4c09-fa5c-2d1a99412cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['how are you', 'who is john', 'who is nice', 'where is john', 'how is john', 'who are you']\n",
            "22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = words_to_tensor(data_words, device=device)\n",
        "print(data)\n",
        "inputs = (torch.rand([1, 3, 224, 224]),)\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU4zddROnBHY",
        "outputId": "aec7e6a5-040f-4cce-9bd0-c286a1257b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1, 18,  8],\n",
            "        [13,  9,  3],\n",
            "        [13,  9,  5],\n",
            "        [16,  9,  3],\n",
            "        [ 1,  9,  3],\n",
            "        [13, 18,  8]])\n",
            "(tensor([[[[0.1463, 0.4157, 0.5475,  ..., 0.6986, 0.6219, 0.4232],\n",
            "          [0.6610, 0.1602, 0.3050,  ..., 0.7941, 0.9032, 0.7078],\n",
            "          [0.9311, 0.8927, 0.4355,  ..., 0.1048, 0.9762, 0.0594],\n",
            "          ...,\n",
            "          [0.8570, 0.3959, 0.8863,  ..., 0.4239, 0.1766, 0.8455],\n",
            "          [0.3627, 0.1462, 0.6186,  ..., 0.9564, 0.1219, 0.9657],\n",
            "          [0.0912, 0.8721, 0.7737,  ..., 0.7030, 0.3683, 0.0751]],\n",
            "\n",
            "         [[0.6171, 0.2647, 0.9825,  ..., 0.8139, 0.1369, 0.6426],\n",
            "          [0.2626, 0.5564, 0.0777,  ..., 0.5878, 0.8443, 0.9217],\n",
            "          [0.7078, 0.2666, 0.2642,  ..., 0.4774, 0.9062, 0.6940],\n",
            "          ...,\n",
            "          [0.1811, 0.8412, 0.7691,  ..., 0.3237, 0.7639, 0.0758],\n",
            "          [0.0236, 0.8368, 0.8537,  ..., 0.8865, 0.0366, 0.3454],\n",
            "          [0.8265, 0.4159, 0.6346,  ..., 0.7632, 0.8657, 0.1218]],\n",
            "\n",
            "         [[0.5737, 0.9185, 0.7709,  ..., 0.2640, 0.8083, 0.3240],\n",
            "          [0.0761, 0.3016, 0.6516,  ..., 0.2775, 0.0191, 0.7463],\n",
            "          [0.5458, 0.4138, 0.0649,  ..., 0.6503, 0.7648, 0.7879],\n",
            "          ...,\n",
            "          [0.5571, 0.7639, 0.7857,  ..., 0.4861, 0.1738, 0.9648],\n",
            "          [0.8361, 0.5857, 0.1557,  ..., 0.2009, 0.2995, 0.8686],\n",
            "          [0.4498, 0.8010, 0.2322,  ..., 0.3145, 0.3914, 0.9574]]]]),)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = (torch.rand([1, 10, 128]),)\n",
        "ep = torch.export.export(model, tuple(inputs))\n",
        "# Visualize\n",
        "model_explorer.visualize_pytorch('mobilenet', exported_program=ep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "IYgPNcyllqQ1",
        "outputId": "16ab4171-08cd-4c3d-9872-2c3b1ae000d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model_explorer' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-85b3c268de79>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Visualize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_explorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_pytorch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mobilenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexported_program\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model_explorer' is not defined"
          ]
        }
      ]
    }
  ]
}