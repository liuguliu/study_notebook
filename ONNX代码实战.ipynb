{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONlJ4ScOaE2va5ip69pmuM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuguliu/study_notebook/blob/main/ONNX%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.定义超分辨模型"
      ],
      "metadata": {
        "id": "S1aMczl1QRiH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG69KnM8QNwX"
      },
      "outputs": [],
      "source": [
        "# 导入相关包\n",
        "import io\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "# 定义超分辨网络\n",
        "class SuperResolutionNet(nn.Module):\n",
        "    def __init__(self, upscale_factor, inplace=False):\n",
        "        super(SuperResolutionNet, self).__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=inplace)\n",
        "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
        "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
        "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
        "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.conv1(x))\n",
        "        x = self.relu(self.conv2(x))\n",
        "        x = self.relu(self.conv3(x))\n",
        "        x = self.pixel_shuffle(self.conv4(x))\n",
        "        return x\n",
        "\n",
        "\t# 模型初始化\n",
        "    def _initialize_weights(self):\n",
        "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
        "        init.orthogonal_(self.conv4.weight)\n",
        "\n",
        "# 实例化模型\n",
        "torch_model = SuperResolutionNet(upscale_factor=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx --quiet\n",
        "!pip install onnxruntime --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqEKHZmxQ0t_",
        "outputId": "68f76c9f-90c1-47a2-95c4-71bae7c75865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. 模型导出为ONNX格式"
      ],
      "metadata": {
        "id": "AlxGc4baQe9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_url = 'https://s3.amazonaws.com/pytorch/test_data/export/superres_epoch100-44c6958e.pth'\n",
        "batch_size = 1    # just a random number\n",
        "# 加载预训练得到权重\n",
        "map_location = lambda storage, loc: storage\n",
        "if torch.cuda.is_available():\n",
        "    map_location = None\n",
        "torch_model.load_state_dict(model_zoo.load_url(model_url, map_location=map_location))\n",
        "\n",
        "# 将模型设置为推理模式\n",
        "torch_model.eval()\n",
        "# Input to the model\n",
        "x = torch.randn(batch_size, 1, 224, 224, requires_grad=True)\n",
        "torch_out = torch_model(x)\n",
        "\n",
        "# 导出模型\n",
        "torch.onnx.export(torch_model,    # model being run\n",
        "        x,             # model input (or a tuple for multiple inputs)\n",
        "        \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "        export_params=True,        # store the trained parameter weights inside the model file\n",
        "        opset_version=10,   # the ONNX version to export the model to\n",
        "        do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "        input_names = ['input'],   # the model's input names\n",
        "        output_names = ['output'], # the model's output names\n",
        "        # variable length axes\n",
        "        dynamic_axes={'input' : {0 : 'batch_size'},\n",
        "                      'output' : {0 : 'batch_size'}})"
      ],
      "metadata": {
        "id": "F-RpPHOPQi6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. 检验ONNX模型"
      ],
      "metadata": {
        "id": "zWMoaCw6RMQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "# 我们可以使用异常处理的方法进行检验\n",
        "try:\n",
        "    # 当我们的模型不可用时，将会报出异常\n",
        "    onnx.checker.check_model(\"super_resolution.onnx\")\n",
        "except onnx.checker.ValidationError as e:\n",
        "    print(\"The model is invalid: %s\"%e)\n",
        "else:\n",
        "    # 模型可用时，将不会报出异常，并会输出“The model is valid!”\n",
        "    print(\"The model is valid!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1MZPYkiRL4x",
        "outputId": "e4c00bd5-3fd6-4f5a-870c-aaa637c3b4a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model is valid!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. 使用ONNX Runtime进行推理"
      ],
      "metadata": {
        "id": "hio_yZ4mRSc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\")\n",
        "\n",
        "# 将张量转化为ndarray格式\n",
        "def to_numpy(tensor):\n",
        "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "\n",
        "# 构建输入的字典和计算输出结果\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# 比较使用PyTorch和ONNX Runtime得出的精度\n",
        "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K3Fz_anARTKH",
        "outputId": "75f36cdc-a7c6-45eb-83d8-1a7313de8270"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. 进行实际预测并可视化"
      ],
      "metadata": {
        "id": "ZjKnl5s9RZCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 读取图片\n",
        "img = Image.open(\"cat_224x224.jpg\")\n",
        "# 对图片进行resize操作\n",
        "resize = transforms.Resize([224, 224])\n",
        "img = resize(img)\n",
        "\n",
        "img_ycbcr = img.convert('YCbCr')\n",
        "img_y, img_cb, img_cr = img_ycbcr.split()\n",
        "\n",
        "to_tensor = transforms.ToTensor()\n",
        "img_y = to_tensor(img_y)\n",
        "img_y.unsqueeze_(0)\n",
        "# 构建输入的字典并将value转换位array格式\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(img_y)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "img_out_y = ort_outs[0]\n",
        "img_out_y = Image.fromarray(np.uint8((img_out_y[0] * 255.0).clip(0, 255)[0]), mode='L')\n",
        "\n",
        "# 保存最后得到的图片\n",
        "final_img = Image.merge(\n",
        "    \"YCbCr\", [\n",
        "        img_out_y,\n",
        "        img_cb.resize(img_out_y.size, Image.BICUBIC),\n",
        "        img_cr.resize(img_out_y.size, Image.BICUBIC),\n",
        "    ]).convert(\"RGB\")\n",
        "\n",
        "final_img.save(\"cat_superres_with_ort.jpg\")"
      ],
      "metadata": {
        "id": "iai_kJcoRZro"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}